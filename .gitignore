training <- read.csv("C:/Users/dell/Desktop/pml-training.csv", na.strings=c("#DIV/0!"), row.names = 1)
testing <- read.csv("C:/Users/dell/Desktop/pml-testing.csv", na.strings=c("#DIV/0!"), row.names = 1)

library(caret)
library(lattice)
library(ggplot2)
library(randomForest)

dim(training)
table(training$classe)
training <- training[, 6:dim(training)[2]]
treshold <- dim(training)[1] * 0.95
goodColumns <- !apply(training, 2, function(x) sum(is.na(x)) > treshold  || sum(x=="") > treshold)

training <- training[, goodColumns]

badColumns <- nearZeroVar(training, saveMetrics = TRUE)

training <- training[, badColumns$nzv==FALSE]

training$classe = factor(training$classe)


inTrain <- createDataPartition(training$classe, p = 0.6)[[1]]
crossv <- training[-inTrain,]
training <- training[ inTrain,]
inTrain <- createDataPartition(crossv$classe, p = 0.75)[[1]]
crossv_test <- crossv[ -inTrain,]
crossv <- crossv[inTrain,]


testing <- testing[, 6:dim(testing)[2]]
testing <- testing[, goodColumns]
testing$classe <- NA
testing <- testing[, badColumns$nzv==FALSE]

mod1 <- train(classe ~ ., data=training, method="rf")
mod2 <- train(classe ~ ., data=training, method="gbm")
mod3 <- train(classe ~ ., data=training, method="lda")

pred1 <- predict(mod1, crossv)
pred2 <- predict(mod2, crossv)
pred3 <- predict(mod3, crossv)


predDF <- data.frame(pred1, pred2, pred3, classe=crossv$classe)
predDF <- data.frame(pred1, pred2, classe=crossv$classe)

combModFit <- train(classe ~ ., method="rf", data=predDF)
combPredIn <- predict(combModFit, predDF)
confusionMatrix(combPredIn, predDF$classe)

pred1 <- predict(mod1, crossv_test)
pred3 <- predict(mod3, crossv_test)
accuracy <- sum(pred1 == crossv_test$classe) / length(pred1)




